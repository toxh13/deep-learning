{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b2e176a-f607-4057-9f5e-756db362f8e0",
      "metadata": {
        "id": "1b2e176a-f607-4057-9f5e-756db362f8e0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f821fe78-6192-4aae-bb27-361e7464ea5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "f821fe78-6192-4aae-bb27-361e7464ea5b",
        "outputId": "73a15b7e-3e43-4314-8073-52d0aec7964b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
              "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
              "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
              "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
              "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
              "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
              "...           ...         ...         ...         ...         ...   \n",
              "9115     8.280854     34.1980     -2.9038   28.080803    5.299132   \n",
              "9116     9.591118     51.6970     -3.4129   35.722025    5.976791   \n",
              "9117     9.599113     27.9300     -1.0765   48.850886    6.989341   \n",
              "9118     9.692482     72.7820     -2.6734   59.378336    7.705734   \n",
              "9119     9.380641     45.0090     -3.5938   40.459334    6.360765   \n",
              "\n",
              "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
              "0       -0.023319     1.083150      1.1832     0.99744    0.002208  ...   \n",
              "1        0.552416     1.140865      1.2129     1.05810    0.000784  ...   \n",
              "2        0.100538     1.140962      1.2128     1.07960    0.000508  ...   \n",
              "3       -0.231914     1.165260      1.3170     1.07870    0.002173  ...   \n",
              "4        2.042285     1.187504      1.2574     1.09450    0.000662  ...   \n",
              "...           ...          ...         ...         ...         ...  ...   \n",
              "9115     1.350075    -1.491537     11.2240   -11.65100   14.670334  ...   \n",
              "9116     2.981144     0.086304      6.9951   -11.76400    5.329897  ...   \n",
              "9117     0.449237    -0.728367      3.7801    -8.36910    5.683022  ...   \n",
              "9118     4.491114    -0.582724      6.1216    -8.85710    4.162963  ...   \n",
              "9119     1.688626    -0.266325      5.8603    -6.91970    4.017098  ...   \n",
              "\n",
              "      LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
              "0        0.000792      0.177075     -0.057119    -0.054963    -0.059241   \n",
              "1        0.000860     -0.286918     -0.057268    -0.054945    -0.059589   \n",
              "2        0.000762     -0.134430     -0.057068    -0.054711    -0.059065   \n",
              "3        0.000735      0.021485     -0.056422    -0.053670    -0.058310   \n",
              "4        0.000824     -0.148229     -0.055801    -0.053313    -0.057815   \n",
              "...           ...           ...           ...          ...          ...   \n",
              "9115     0.200829     -0.040701      0.297666     0.708480    -0.117430   \n",
              "9116     0.148745     -0.266377      0.224716     0.554670    -0.250950   \n",
              "9117     0.310748     -0.009505     -0.237786     0.088854    -0.477260   \n",
              "9118     0.156493      0.050624      0.533023     0.677800     0.055941   \n",
              "9119     0.229154     -0.342228      0.491919     0.707920     0.251280   \n",
              "\n",
              "       LL_zmag_var  LL_zmag_std  LL_zmag_skew    activity  people  \n",
              "0     6.778722e-07     0.000823      0.036729     sitting      p1  \n",
              "1     7.032302e-07     0.000839      0.347471     sitting      p1  \n",
              "2     6.268222e-07     0.000792      0.045579     sitting      p1  \n",
              "3     8.011245e-07     0.000895      0.240690     sitting      p1  \n",
              "4     6.853423e-07     0.000828      0.258429     sitting      p1  \n",
              "...            ...          ...           ...         ...     ...  \n",
              "9115  4.135451e-02     0.203358     -0.310022  basketBall      p8  \n",
              "9116  3.355704e-02     0.183186     -0.736410  basketBall      p8  \n",
              "9117  2.026107e-02     0.142341      0.668438  basketBall      p8  \n",
              "9118  1.356379e-02     0.116464     -1.482489  basketBall      p8  \n",
              "9119  9.358254e-03     0.096738     -0.223302  basketBall      p8  \n",
              "\n",
              "[9120 rows x 272 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6e57544-f53d-4e9d-bb8b-9f00b3d40bb4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T_xacc_mean</th>\n",
              "      <th>T_xacc_max</th>\n",
              "      <th>T_xacc_min</th>\n",
              "      <th>T_xacc_var</th>\n",
              "      <th>T_xacc_std</th>\n",
              "      <th>T_xacc_skew</th>\n",
              "      <th>T_yacc_mean</th>\n",
              "      <th>T_yacc_max</th>\n",
              "      <th>T_yacc_min</th>\n",
              "      <th>T_yacc_var</th>\n",
              "      <th>...</th>\n",
              "      <th>LL_ymag_std</th>\n",
              "      <th>LL_ymag_skew</th>\n",
              "      <th>LL_zmag_mean</th>\n",
              "      <th>LL_zmag_max</th>\n",
              "      <th>LL_zmag_min</th>\n",
              "      <th>LL_zmag_var</th>\n",
              "      <th>LL_zmag_std</th>\n",
              "      <th>LL_zmag_skew</th>\n",
              "      <th>activity</th>\n",
              "      <th>people</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.975714</td>\n",
              "      <td>8.1605</td>\n",
              "      <td>7.6823</td>\n",
              "      <td>0.014395</td>\n",
              "      <td>0.119981</td>\n",
              "      <td>-0.023319</td>\n",
              "      <td>1.083150</td>\n",
              "      <td>1.1832</td>\n",
              "      <td>0.99744</td>\n",
              "      <td>0.002208</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000792</td>\n",
              "      <td>0.177075</td>\n",
              "      <td>-0.057119</td>\n",
              "      <td>-0.054963</td>\n",
              "      <td>-0.059241</td>\n",
              "      <td>6.778722e-07</td>\n",
              "      <td>0.000823</td>\n",
              "      <td>0.036729</td>\n",
              "      <td>sitting</td>\n",
              "      <td>p1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.978250</td>\n",
              "      <td>8.1763</td>\n",
              "      <td>7.8472</td>\n",
              "      <td>0.007551</td>\n",
              "      <td>0.086896</td>\n",
              "      <td>0.552416</td>\n",
              "      <td>1.140865</td>\n",
              "      <td>1.2129</td>\n",
              "      <td>1.05810</td>\n",
              "      <td>0.000784</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000860</td>\n",
              "      <td>-0.286918</td>\n",
              "      <td>-0.057268</td>\n",
              "      <td>-0.054945</td>\n",
              "      <td>-0.059589</td>\n",
              "      <td>7.032302e-07</td>\n",
              "      <td>0.000839</td>\n",
              "      <td>0.347471</td>\n",
              "      <td>sitting</td>\n",
              "      <td>p1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.970894</td>\n",
              "      <td>8.0860</td>\n",
              "      <td>7.8470</td>\n",
              "      <td>0.003092</td>\n",
              "      <td>0.055603</td>\n",
              "      <td>0.100538</td>\n",
              "      <td>1.140962</td>\n",
              "      <td>1.2128</td>\n",
              "      <td>1.07960</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000762</td>\n",
              "      <td>-0.134430</td>\n",
              "      <td>-0.057068</td>\n",
              "      <td>-0.054711</td>\n",
              "      <td>-0.059065</td>\n",
              "      <td>6.268222e-07</td>\n",
              "      <td>0.000792</td>\n",
              "      <td>0.045579</td>\n",
              "      <td>sitting</td>\n",
              "      <td>p1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.938412</td>\n",
              "      <td>8.1083</td>\n",
              "      <td>7.6901</td>\n",
              "      <td>0.003763</td>\n",
              "      <td>0.061343</td>\n",
              "      <td>-0.231914</td>\n",
              "      <td>1.165260</td>\n",
              "      <td>1.3170</td>\n",
              "      <td>1.07870</td>\n",
              "      <td>0.002173</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>0.021485</td>\n",
              "      <td>-0.056422</td>\n",
              "      <td>-0.053670</td>\n",
              "      <td>-0.058310</td>\n",
              "      <td>8.011245e-07</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>0.240690</td>\n",
              "      <td>sitting</td>\n",
              "      <td>p1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.908930</td>\n",
              "      <td>8.1305</td>\n",
              "      <td>7.8322</td>\n",
              "      <td>0.001741</td>\n",
              "      <td>0.041731</td>\n",
              "      <td>2.042285</td>\n",
              "      <td>1.187504</td>\n",
              "      <td>1.2574</td>\n",
              "      <td>1.09450</td>\n",
              "      <td>0.000662</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000824</td>\n",
              "      <td>-0.148229</td>\n",
              "      <td>-0.055801</td>\n",
              "      <td>-0.053313</td>\n",
              "      <td>-0.057815</td>\n",
              "      <td>6.853423e-07</td>\n",
              "      <td>0.000828</td>\n",
              "      <td>0.258429</td>\n",
              "      <td>sitting</td>\n",
              "      <td>p1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9115</th>\n",
              "      <td>8.280854</td>\n",
              "      <td>34.1980</td>\n",
              "      <td>-2.9038</td>\n",
              "      <td>28.080803</td>\n",
              "      <td>5.299132</td>\n",
              "      <td>1.350075</td>\n",
              "      <td>-1.491537</td>\n",
              "      <td>11.2240</td>\n",
              "      <td>-11.65100</td>\n",
              "      <td>14.670334</td>\n",
              "      <td>...</td>\n",
              "      <td>0.200829</td>\n",
              "      <td>-0.040701</td>\n",
              "      <td>0.297666</td>\n",
              "      <td>0.708480</td>\n",
              "      <td>-0.117430</td>\n",
              "      <td>4.135451e-02</td>\n",
              "      <td>0.203358</td>\n",
              "      <td>-0.310022</td>\n",
              "      <td>basketBall</td>\n",
              "      <td>p8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9116</th>\n",
              "      <td>9.591118</td>\n",
              "      <td>51.6970</td>\n",
              "      <td>-3.4129</td>\n",
              "      <td>35.722025</td>\n",
              "      <td>5.976791</td>\n",
              "      <td>2.981144</td>\n",
              "      <td>0.086304</td>\n",
              "      <td>6.9951</td>\n",
              "      <td>-11.76400</td>\n",
              "      <td>5.329897</td>\n",
              "      <td>...</td>\n",
              "      <td>0.148745</td>\n",
              "      <td>-0.266377</td>\n",
              "      <td>0.224716</td>\n",
              "      <td>0.554670</td>\n",
              "      <td>-0.250950</td>\n",
              "      <td>3.355704e-02</td>\n",
              "      <td>0.183186</td>\n",
              "      <td>-0.736410</td>\n",
              "      <td>basketBall</td>\n",
              "      <td>p8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9117</th>\n",
              "      <td>9.599113</td>\n",
              "      <td>27.9300</td>\n",
              "      <td>-1.0765</td>\n",
              "      <td>48.850886</td>\n",
              "      <td>6.989341</td>\n",
              "      <td>0.449237</td>\n",
              "      <td>-0.728367</td>\n",
              "      <td>3.7801</td>\n",
              "      <td>-8.36910</td>\n",
              "      <td>5.683022</td>\n",
              "      <td>...</td>\n",
              "      <td>0.310748</td>\n",
              "      <td>-0.009505</td>\n",
              "      <td>-0.237786</td>\n",
              "      <td>0.088854</td>\n",
              "      <td>-0.477260</td>\n",
              "      <td>2.026107e-02</td>\n",
              "      <td>0.142341</td>\n",
              "      <td>0.668438</td>\n",
              "      <td>basketBall</td>\n",
              "      <td>p8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9118</th>\n",
              "      <td>9.692482</td>\n",
              "      <td>72.7820</td>\n",
              "      <td>-2.6734</td>\n",
              "      <td>59.378336</td>\n",
              "      <td>7.705734</td>\n",
              "      <td>4.491114</td>\n",
              "      <td>-0.582724</td>\n",
              "      <td>6.1216</td>\n",
              "      <td>-8.85710</td>\n",
              "      <td>4.162963</td>\n",
              "      <td>...</td>\n",
              "      <td>0.156493</td>\n",
              "      <td>0.050624</td>\n",
              "      <td>0.533023</td>\n",
              "      <td>0.677800</td>\n",
              "      <td>0.055941</td>\n",
              "      <td>1.356379e-02</td>\n",
              "      <td>0.116464</td>\n",
              "      <td>-1.482489</td>\n",
              "      <td>basketBall</td>\n",
              "      <td>p8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9119</th>\n",
              "      <td>9.380641</td>\n",
              "      <td>45.0090</td>\n",
              "      <td>-3.5938</td>\n",
              "      <td>40.459334</td>\n",
              "      <td>6.360765</td>\n",
              "      <td>1.688626</td>\n",
              "      <td>-0.266325</td>\n",
              "      <td>5.8603</td>\n",
              "      <td>-6.91970</td>\n",
              "      <td>4.017098</td>\n",
              "      <td>...</td>\n",
              "      <td>0.229154</td>\n",
              "      <td>-0.342228</td>\n",
              "      <td>0.491919</td>\n",
              "      <td>0.707920</td>\n",
              "      <td>0.251280</td>\n",
              "      <td>9.358254e-03</td>\n",
              "      <td>0.096738</td>\n",
              "      <td>-0.223302</td>\n",
              "      <td>basketBall</td>\n",
              "      <td>p8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9120 rows × 272 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6e57544-f53d-4e9d-bb8b-9f00b3d40bb4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6e57544-f53d-4e9d-bb8b-9f00b3d40bb4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6e57544-f53d-4e9d-bb8b-9f00b3d40bb4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f95883c9-b000-4f52-8ac6-b80edc751a0b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f95883c9-b000-4f52-8ac6-b80edc751a0b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f95883c9-b000-4f52-8ac6-b80edc751a0b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_31e9f393-9d43-4e97-9c07-c5e0d966185e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_31e9f393-9d43-4e97-9c07-c5e0d966185e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df=pd.read_csv('DSA_features.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9be83200-743c-4c66-bbe9-1bea7cb10f17",
      "metadata": {
        "id": "9be83200-743c-4c66-bbe9-1bea7cb10f17"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['activity', 'people'])\n",
        "y = df['activity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "317b24cb-292f-46a0-87c1-ce0454e6c497",
      "metadata": {
        "id": "317b24cb-292f-46a0-87c1-ce0454e6c497"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e8d9de6-6893-4cbd-a2b4-d0f641c6a9cb",
      "metadata": {
        "id": "4e8d9de6-6893-4cbd-a2b4-d0f641c6a9cb"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc64eb10-1cb2-4d95-9886-f9af778475e8",
      "metadata": {
        "id": "dc64eb10-1cb2-4d95-9886-f9af778475e8"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d9216cc-3e14-427d-9d3d-8bbb4796fc1c",
      "metadata": {
        "id": "5d9216cc-3e14-427d-9d3d-8bbb4796fc1c"
      },
      "outputs": [],
      "source": [
        "X_train_scaled = np.expand_dims(X_train_scaled, axis=-1)\n",
        "X_test_scaled = np.expand_dims(X_test_scaled, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7164d6e2-b721-4f35-b1a3-ef2a5afb9360",
      "metadata": {
        "id": "7164d6e2-b721-4f35-b1a3-ef2a5afb9360"
      },
      "outputs": [],
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Attention and Normalization\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    return x + res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51f81f23-3fc5-4a5b-8239-87f61f97d8fd",
      "metadata": {
        "id": "51f81f23-3fc5-4a5b-8239-87f61f97d8fd"
      },
      "outputs": [],
      "source": [
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_last\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2022f653-c6ec-4db7-bb37-a35894057bad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1777
        },
        "id": "2022f653-c6ec-4db7-bb37-a35894057bad",
        "outputId": "c0fdf6ea-2f65-4b1a-9089-6ac9f10c16bb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m7,169\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m8\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m5\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "│                           │                        │                │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m7,169\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n",
              "│                           │                        │                │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m8\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m5\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n",
              "│                           │                        │                │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m7,169\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_4… │\n",
              "│                           │                        │                │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m8\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m5\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n",
              "│                           │                        │                │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m7,169\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_6… │\n",
              "│                           │                        │                │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m8\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m5\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_7… │\n",
              "│                           │                        │                │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │            \u001b[38;5;34m256\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)             │          \u001b[38;5;34m2,451\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "│                           │                        │                │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n",
              "│                           │                        │                │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n",
              "│                           │                        │                │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4… │\n",
              "│                           │                        │                │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n",
              "│                           │                        │                │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6… │\n",
              "│                           │                        │                │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_7… │\n",
              "│                           │                        │                │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,451\u001b[0m (122.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,451</span> (122.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,451\u001b[0m (122.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,451</span> (122.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "input_shape = X_train_scaled.shape[1:]\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ab22146-1bb9-40f9-847a-f16dbbd5621c",
      "metadata": {
        "id": "9ab22146-1bb9-40f9-847a-f16dbbd5621c"
      },
      "outputs": [],
      "source": [
        "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "051f30ce-ca5f-4c90-bc1d-6efe0eab4983",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "051f30ce-ca5f-4c90-bc1d-6efe0eab4983",
        "outputId": "9b992161-6475-4d9b-e011-c50679ba6934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 323ms/step - loss: 2.9317 - sparse_categorical_accuracy: 0.0712 - val_loss: 2.9208 - val_sparse_categorical_accuracy: 0.0788\n",
            "Epoch 2/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - loss: 2.9155 - sparse_categorical_accuracy: 0.0969 - val_loss: 2.9059 - val_sparse_categorical_accuracy: 0.1171\n",
            "Epoch 3/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 125ms/step - loss: 2.8985 - sparse_categorical_accuracy: 0.1018 - val_loss: 2.8904 - val_sparse_categorical_accuracy: 0.1178\n",
            "Epoch 4/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.8835 - sparse_categorical_accuracy: 0.1154 - val_loss: 2.8737 - val_sparse_categorical_accuracy: 0.1130\n",
            "Epoch 5/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 123ms/step - loss: 2.8676 - sparse_categorical_accuracy: 0.1138 - val_loss: 2.8557 - val_sparse_categorical_accuracy: 0.1027\n",
            "Epoch 6/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.8456 - sparse_categorical_accuracy: 0.1188 - val_loss: 2.8358 - val_sparse_categorical_accuracy: 0.0979\n",
            "Epoch 7/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.8254 - sparse_categorical_accuracy: 0.1114 - val_loss: 2.8145 - val_sparse_categorical_accuracy: 0.0966\n",
            "Epoch 8/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.7989 - sparse_categorical_accuracy: 0.1128 - val_loss: 2.7923 - val_sparse_categorical_accuracy: 0.0986\n",
            "Epoch 9/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.7726 - sparse_categorical_accuracy: 0.1255 - val_loss: 2.7693 - val_sparse_categorical_accuracy: 0.0979\n",
            "Epoch 10/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 2.7552 - sparse_categorical_accuracy: 0.1180 - val_loss: 2.7465 - val_sparse_categorical_accuracy: 0.1007\n",
            "Epoch 11/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 2.7297 - sparse_categorical_accuracy: 0.1225 - val_loss: 2.7236 - val_sparse_categorical_accuracy: 0.1048\n",
            "Epoch 12/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 2.7092 - sparse_categorical_accuracy: 0.1118 - val_loss: 2.7012 - val_sparse_categorical_accuracy: 0.1048\n",
            "Epoch 13/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.6832 - sparse_categorical_accuracy: 0.1223 - val_loss: 2.6794 - val_sparse_categorical_accuracy: 0.1062\n",
            "Epoch 14/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 122ms/step - loss: 2.6634 - sparse_categorical_accuracy: 0.1171 - val_loss: 2.6581 - val_sparse_categorical_accuracy: 0.1110\n",
            "Epoch 15/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 2.6382 - sparse_categorical_accuracy: 0.1252 - val_loss: 2.6376 - val_sparse_categorical_accuracy: 0.1110\n",
            "Epoch 16/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 2.6116 - sparse_categorical_accuracy: 0.1304 - val_loss: 2.6178 - val_sparse_categorical_accuracy: 0.1116\n",
            "Epoch 17/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.5963 - sparse_categorical_accuracy: 0.1246 - val_loss: 2.5991 - val_sparse_categorical_accuracy: 0.1137\n",
            "Epoch 18/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 122ms/step - loss: 2.5851 - sparse_categorical_accuracy: 0.1357 - val_loss: 2.5809 - val_sparse_categorical_accuracy: 0.1151\n",
            "Epoch 19/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 2.5584 - sparse_categorical_accuracy: 0.1434 - val_loss: 2.5634 - val_sparse_categorical_accuracy: 0.1164\n",
            "Epoch 20/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.5373 - sparse_categorical_accuracy: 0.1343 - val_loss: 2.5468 - val_sparse_categorical_accuracy: 0.1158\n",
            "Epoch 21/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 2.5281 - sparse_categorical_accuracy: 0.1407 - val_loss: 2.5309 - val_sparse_categorical_accuracy: 0.1171\n",
            "Epoch 22/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.5059 - sparse_categorical_accuracy: 0.1377 - val_loss: 2.5152 - val_sparse_categorical_accuracy: 0.1219\n",
            "Epoch 23/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 2.4881 - sparse_categorical_accuracy: 0.1502 - val_loss: 2.5003 - val_sparse_categorical_accuracy: 0.1274\n",
            "Epoch 24/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.4858 - sparse_categorical_accuracy: 0.1463 - val_loss: 2.4861 - val_sparse_categorical_accuracy: 0.1308\n",
            "Epoch 25/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 2.4698 - sparse_categorical_accuracy: 0.1613 - val_loss: 2.4721 - val_sparse_categorical_accuracy: 0.1411\n",
            "Epoch 26/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.4559 - sparse_categorical_accuracy: 0.1528 - val_loss: 2.4588 - val_sparse_categorical_accuracy: 0.1370\n",
            "Epoch 27/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 122ms/step - loss: 2.4487 - sparse_categorical_accuracy: 0.1492 - val_loss: 2.4456 - val_sparse_categorical_accuracy: 0.1459\n",
            "Epoch 28/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.4373 - sparse_categorical_accuracy: 0.1470 - val_loss: 2.4333 - val_sparse_categorical_accuracy: 0.1466\n",
            "Epoch 29/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 125ms/step - loss: 2.4163 - sparse_categorical_accuracy: 0.1522 - val_loss: 2.4208 - val_sparse_categorical_accuracy: 0.1596\n",
            "Epoch 30/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.4061 - sparse_categorical_accuracy: 0.1751 - val_loss: 2.4092 - val_sparse_categorical_accuracy: 0.1589\n",
            "Epoch 31/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.3938 - sparse_categorical_accuracy: 0.1707 - val_loss: 2.3980 - val_sparse_categorical_accuracy: 0.1610\n",
            "Epoch 32/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 122ms/step - loss: 2.3885 - sparse_categorical_accuracy: 0.1670 - val_loss: 2.3875 - val_sparse_categorical_accuracy: 0.1603\n",
            "Epoch 33/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.3570 - sparse_categorical_accuracy: 0.1740 - val_loss: 2.3765 - val_sparse_categorical_accuracy: 0.1664\n",
            "Epoch 34/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.3611 - sparse_categorical_accuracy: 0.1818 - val_loss: 2.3664 - val_sparse_categorical_accuracy: 0.1658\n",
            "Epoch 35/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 2.3600 - sparse_categorical_accuracy: 0.1756 - val_loss: 2.3569 - val_sparse_categorical_accuracy: 0.1740\n",
            "Epoch 36/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.3384 - sparse_categorical_accuracy: 0.1704 - val_loss: 2.3475 - val_sparse_categorical_accuracy: 0.1726\n",
            "Epoch 37/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 121ms/step - loss: 2.3312 - sparse_categorical_accuracy: 0.1895 - val_loss: 2.3373 - val_sparse_categorical_accuracy: 0.1801\n",
            "Epoch 38/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.3237 - sparse_categorical_accuracy: 0.1859 - val_loss: 2.3286 - val_sparse_categorical_accuracy: 0.1788\n",
            "Epoch 39/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 123ms/step - loss: 2.3129 - sparse_categorical_accuracy: 0.1878 - val_loss: 2.3200 - val_sparse_categorical_accuracy: 0.1788\n",
            "Epoch 40/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 123ms/step - loss: 2.3079 - sparse_categorical_accuracy: 0.1809 - val_loss: 2.3119 - val_sparse_categorical_accuracy: 0.1815\n",
            "Epoch 41/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.2949 - sparse_categorical_accuracy: 0.1822 - val_loss: 2.3040 - val_sparse_categorical_accuracy: 0.1829\n",
            "Epoch 42/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.2915 - sparse_categorical_accuracy: 0.1811 - val_loss: 2.2969 - val_sparse_categorical_accuracy: 0.1795\n",
            "Epoch 43/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 123ms/step - loss: 2.2848 - sparse_categorical_accuracy: 0.1835 - val_loss: 2.2890 - val_sparse_categorical_accuracy: 0.1856\n",
            "Epoch 44/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 123ms/step - loss: 2.2846 - sparse_categorical_accuracy: 0.1817 - val_loss: 2.2816 - val_sparse_categorical_accuracy: 0.1918\n",
            "Epoch 45/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.2716 - sparse_categorical_accuracy: 0.1772 - val_loss: 2.2753 - val_sparse_categorical_accuracy: 0.1856\n",
            "Epoch 46/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 2.2650 - sparse_categorical_accuracy: 0.1940 - val_loss: 2.2687 - val_sparse_categorical_accuracy: 0.1856\n",
            "Epoch 47/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 2.2588 - sparse_categorical_accuracy: 0.1939 - val_loss: 2.2618 - val_sparse_categorical_accuracy: 0.1986\n",
            "Epoch 48/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 2.2435 - sparse_categorical_accuracy: 0.1955 - val_loss: 2.2559 - val_sparse_categorical_accuracy: 0.1911\n",
            "Epoch 49/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 2.2484 - sparse_categorical_accuracy: 0.1867 - val_loss: 2.2496 - val_sparse_categorical_accuracy: 0.1959\n",
            "Epoch 50/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.2404 - sparse_categorical_accuracy: 0.1899 - val_loss: 2.2437 - val_sparse_categorical_accuracy: 0.1959\n",
            "Epoch 51/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.2357 - sparse_categorical_accuracy: 0.1945 - val_loss: 2.2383 - val_sparse_categorical_accuracy: 0.1911\n",
            "Epoch 52/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.2365 - sparse_categorical_accuracy: 0.1821 - val_loss: 2.2334 - val_sparse_categorical_accuracy: 0.1979\n",
            "Epoch 53/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.2331 - sparse_categorical_accuracy: 0.1814 - val_loss: 2.2280 - val_sparse_categorical_accuracy: 0.1938\n",
            "Epoch 54/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 123ms/step - loss: 2.2191 - sparse_categorical_accuracy: 0.1985 - val_loss: 2.2226 - val_sparse_categorical_accuracy: 0.1973\n",
            "Epoch 55/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 2.2178 - sparse_categorical_accuracy: 0.1988 - val_loss: 2.2180 - val_sparse_categorical_accuracy: 0.1979\n",
            "Epoch 56/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.2181 - sparse_categorical_accuracy: 0.2018 - val_loss: 2.2130 - val_sparse_categorical_accuracy: 0.1986\n",
            "Epoch 57/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 2.2077 - sparse_categorical_accuracy: 0.1988 - val_loss: 2.2082 - val_sparse_categorical_accuracy: 0.2096\n",
            "Epoch 58/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.2012 - sparse_categorical_accuracy: 0.2013 - val_loss: 2.2041 - val_sparse_categorical_accuracy: 0.2144\n",
            "Epoch 59/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 122ms/step - loss: 2.2043 - sparse_categorical_accuracy: 0.2026 - val_loss: 2.1999 - val_sparse_categorical_accuracy: 0.2055\n",
            "Epoch 60/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.1901 - sparse_categorical_accuracy: 0.2088 - val_loss: 2.1956 - val_sparse_categorical_accuracy: 0.2082\n",
            "Epoch 61/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.1823 - sparse_categorical_accuracy: 0.1969 - val_loss: 2.1914 - val_sparse_categorical_accuracy: 0.2096\n",
            "Epoch 62/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.1866 - sparse_categorical_accuracy: 0.2051 - val_loss: 2.1874 - val_sparse_categorical_accuracy: 0.2096\n",
            "Epoch 63/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.1783 - sparse_categorical_accuracy: 0.2055 - val_loss: 2.1837 - val_sparse_categorical_accuracy: 0.2240\n",
            "Epoch 64/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 2.1887 - sparse_categorical_accuracy: 0.2116 - val_loss: 2.1802 - val_sparse_categorical_accuracy: 0.2247\n",
            "Epoch 65/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 125ms/step - loss: 2.1694 - sparse_categorical_accuracy: 0.1927 - val_loss: 2.1767 - val_sparse_categorical_accuracy: 0.2192\n",
            "Epoch 66/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.1738 - sparse_categorical_accuracy: 0.2049 - val_loss: 2.1733 - val_sparse_categorical_accuracy: 0.2178\n",
            "Epoch 67/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.1627 - sparse_categorical_accuracy: 0.2067 - val_loss: 2.1699 - val_sparse_categorical_accuracy: 0.2247\n",
            "Epoch 68/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 2.1508 - sparse_categorical_accuracy: 0.2044 - val_loss: 2.1667 - val_sparse_categorical_accuracy: 0.2185\n",
            "Epoch 69/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 125ms/step - loss: 2.1689 - sparse_categorical_accuracy: 0.2054 - val_loss: 2.1643 - val_sparse_categorical_accuracy: 0.2329\n",
            "Epoch 70/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.1627 - sparse_categorical_accuracy: 0.2006 - val_loss: 2.1606 - val_sparse_categorical_accuracy: 0.2377\n",
            "Epoch 71/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 122ms/step - loss: 2.1632 - sparse_categorical_accuracy: 0.1997 - val_loss: 2.1574 - val_sparse_categorical_accuracy: 0.2336\n",
            "Epoch 72/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 124ms/step - loss: 2.1574 - sparse_categorical_accuracy: 0.2062 - val_loss: 2.1549 - val_sparse_categorical_accuracy: 0.2226\n",
            "Epoch 73/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 123ms/step - loss: 2.1489 - sparse_categorical_accuracy: 0.1987 - val_loss: 2.1521 - val_sparse_categorical_accuracy: 0.2226\n",
            "Epoch 74/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.1515 - sparse_categorical_accuracy: 0.2022 - val_loss: 2.1493 - val_sparse_categorical_accuracy: 0.2356\n",
            "Epoch 75/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.1491 - sparse_categorical_accuracy: 0.1999 - val_loss: 2.1469 - val_sparse_categorical_accuracy: 0.2356\n",
            "Epoch 76/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 2.1516 - sparse_categorical_accuracy: 0.2001 - val_loss: 2.1450 - val_sparse_categorical_accuracy: 0.2240\n",
            "Epoch 77/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 123ms/step - loss: 2.1228 - sparse_categorical_accuracy: 0.2039 - val_loss: 2.1424 - val_sparse_categorical_accuracy: 0.2281\n",
            "Epoch 78/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 2.1412 - sparse_categorical_accuracy: 0.2005 - val_loss: 2.1399 - val_sparse_categorical_accuracy: 0.2356\n",
            "Epoch 79/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 2.1345 - sparse_categorical_accuracy: 0.2011 - val_loss: 2.1376 - val_sparse_categorical_accuracy: 0.2342\n",
            "Epoch 80/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.1288 - sparse_categorical_accuracy: 0.2059 - val_loss: 2.1353 - val_sparse_categorical_accuracy: 0.2384\n",
            "Epoch 81/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 2.1366 - sparse_categorical_accuracy: 0.2007 - val_loss: 2.1332 - val_sparse_categorical_accuracy: 0.2342\n",
            "Epoch 82/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 123ms/step - loss: 2.1294 - sparse_categorical_accuracy: 0.1994 - val_loss: 2.1311 - val_sparse_categorical_accuracy: 0.2466\n",
            "Epoch 83/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 2.1374 - sparse_categorical_accuracy: 0.2054 - val_loss: 2.1290 - val_sparse_categorical_accuracy: 0.2349\n",
            "Epoch 84/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.1429 - sparse_categorical_accuracy: 0.1993 - val_loss: 2.1272 - val_sparse_categorical_accuracy: 0.2329\n",
            "Epoch 85/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 2.1210 - sparse_categorical_accuracy: 0.2040 - val_loss: 2.1252 - val_sparse_categorical_accuracy: 0.2432\n",
            "Epoch 86/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.1309 - sparse_categorical_accuracy: 0.2083 - val_loss: 2.1232 - val_sparse_categorical_accuracy: 0.2397\n",
            "Epoch 87/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 122ms/step - loss: 2.1222 - sparse_categorical_accuracy: 0.2098 - val_loss: 2.1215 - val_sparse_categorical_accuracy: 0.2397\n",
            "Epoch 88/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - loss: 2.1068 - sparse_categorical_accuracy: 0.2064 - val_loss: 2.1198 - val_sparse_categorical_accuracy: 0.2370\n",
            "Epoch 89/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.1130 - sparse_categorical_accuracy: 0.2071 - val_loss: 2.1182 - val_sparse_categorical_accuracy: 0.2425\n",
            "Epoch 90/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 125ms/step - loss: 2.1110 - sparse_categorical_accuracy: 0.2091 - val_loss: 2.1161 - val_sparse_categorical_accuracy: 0.2486\n",
            "Epoch 91/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.1077 - sparse_categorical_accuracy: 0.2031 - val_loss: 2.1145 - val_sparse_categorical_accuracy: 0.2445\n",
            "Epoch 92/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 122ms/step - loss: 2.1111 - sparse_categorical_accuracy: 0.2025 - val_loss: 2.1131 - val_sparse_categorical_accuracy: 0.2479\n",
            "Epoch 93/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.1042 - sparse_categorical_accuracy: 0.2007 - val_loss: 2.1115 - val_sparse_categorical_accuracy: 0.2459\n",
            "Epoch 94/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 2.1078 - sparse_categorical_accuracy: 0.2135 - val_loss: 2.1100 - val_sparse_categorical_accuracy: 0.2486\n",
            "Epoch 95/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.1054 - sparse_categorical_accuracy: 0.2121 - val_loss: 2.1089 - val_sparse_categorical_accuracy: 0.2445\n",
            "Epoch 96/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 2.0955 - sparse_categorical_accuracy: 0.2135 - val_loss: 2.1069 - val_sparse_categorical_accuracy: 0.2493\n",
            "Epoch 97/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.1060 - sparse_categorical_accuracy: 0.2130 - val_loss: 2.1069 - val_sparse_categorical_accuracy: 0.2363\n",
            "Epoch 98/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 2.1044 - sparse_categorical_accuracy: 0.2078 - val_loss: 2.1048 - val_sparse_categorical_accuracy: 0.2411\n",
            "Epoch 99/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 2.0958 - sparse_categorical_accuracy: 0.2059 - val_loss: 2.1036 - val_sparse_categorical_accuracy: 0.2432\n",
            "Epoch 100/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 2.0979 - sparse_categorical_accuracy: 0.2021 - val_loss: 2.1022 - val_sparse_categorical_accuracy: 0.2445\n",
            "Epoch 101/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 125ms/step - loss: 2.1024 - sparse_categorical_accuracy: 0.2037 - val_loss: 2.1005 - val_sparse_categorical_accuracy: 0.2452\n",
            "Epoch 102/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - loss: 2.0914 - sparse_categorical_accuracy: 0.1994 - val_loss: 2.0998 - val_sparse_categorical_accuracy: 0.2452\n",
            "Epoch 103/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.0880 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.0986 - val_sparse_categorical_accuracy: 0.2432\n",
            "Epoch 104/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 2.1022 - sparse_categorical_accuracy: 0.2118 - val_loss: 2.0966 - val_sparse_categorical_accuracy: 0.2507\n",
            "Epoch 105/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 2.0965 - sparse_categorical_accuracy: 0.2012 - val_loss: 2.0961 - val_sparse_categorical_accuracy: 0.2514\n",
            "Epoch 106/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 125ms/step - loss: 2.1052 - sparse_categorical_accuracy: 0.2051 - val_loss: 2.0948 - val_sparse_categorical_accuracy: 0.2500\n",
            "Epoch 107/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 2.0794 - sparse_categorical_accuracy: 0.2048 - val_loss: 2.0934 - val_sparse_categorical_accuracy: 0.2500\n",
            "Epoch 108/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.1019 - sparse_categorical_accuracy: 0.2088 - val_loss: 2.0925 - val_sparse_categorical_accuracy: 0.2500\n",
            "Epoch 109/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 122ms/step - loss: 2.0883 - sparse_categorical_accuracy: 0.2183 - val_loss: 2.0916 - val_sparse_categorical_accuracy: 0.2404\n",
            "Epoch 110/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 2.0985 - sparse_categorical_accuracy: 0.2043 - val_loss: 2.0904 - val_sparse_categorical_accuracy: 0.2411\n",
            "Epoch 111/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.0861 - sparse_categorical_accuracy: 0.2119 - val_loss: 2.0897 - val_sparse_categorical_accuracy: 0.2459\n",
            "Epoch 112/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.0852 - sparse_categorical_accuracy: 0.2144 - val_loss: 2.0891 - val_sparse_categorical_accuracy: 0.2459\n",
            "Epoch 113/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 123ms/step - loss: 2.0769 - sparse_categorical_accuracy: 0.2203 - val_loss: 2.0870 - val_sparse_categorical_accuracy: 0.2445\n",
            "Epoch 114/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.0925 - sparse_categorical_accuracy: 0.2048 - val_loss: 2.0868 - val_sparse_categorical_accuracy: 0.2473\n",
            "Epoch 115/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 2.0978 - sparse_categorical_accuracy: 0.2008 - val_loss: 2.0853 - val_sparse_categorical_accuracy: 0.2534\n",
            "Epoch 116/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.0896 - sparse_categorical_accuracy: 0.2132 - val_loss: 2.0851 - val_sparse_categorical_accuracy: 0.2486\n",
            "Epoch 117/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 2.0727 - sparse_categorical_accuracy: 0.2168 - val_loss: 2.0833 - val_sparse_categorical_accuracy: 0.2514\n",
            "Epoch 118/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 2.0922 - sparse_categorical_accuracy: 0.2032 - val_loss: 2.0826 - val_sparse_categorical_accuracy: 0.2466\n",
            "Epoch 119/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.0899 - sparse_categorical_accuracy: 0.1942 - val_loss: 2.0820 - val_sparse_categorical_accuracy: 0.2452\n",
            "Epoch 120/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 2.0824 - sparse_categorical_accuracy: 0.2038 - val_loss: 2.0818 - val_sparse_categorical_accuracy: 0.2452\n",
            "Epoch 121/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.0752 - sparse_categorical_accuracy: 0.2178 - val_loss: 2.0807 - val_sparse_categorical_accuracy: 0.2459\n",
            "Epoch 122/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 2.0743 - sparse_categorical_accuracy: 0.2200 - val_loss: 2.0795 - val_sparse_categorical_accuracy: 0.2452\n",
            "Epoch 123/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 2.0792 - sparse_categorical_accuracy: 0.2096 - val_loss: 2.0785 - val_sparse_categorical_accuracy: 0.2493\n",
            "Epoch 124/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.0611 - sparse_categorical_accuracy: 0.2173 - val_loss: 2.0787 - val_sparse_categorical_accuracy: 0.2507\n",
            "Epoch 125/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 122ms/step - loss: 2.0689 - sparse_categorical_accuracy: 0.2196 - val_loss: 2.0779 - val_sparse_categorical_accuracy: 0.2493\n",
            "Epoch 126/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.0881 - sparse_categorical_accuracy: 0.2106 - val_loss: 2.0761 - val_sparse_categorical_accuracy: 0.2466\n",
            "Epoch 127/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 2.0789 - sparse_categorical_accuracy: 0.2102 - val_loss: 2.0760 - val_sparse_categorical_accuracy: 0.2445\n",
            "Epoch 128/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 2.0593 - sparse_categorical_accuracy: 0.2123 - val_loss: 2.0747 - val_sparse_categorical_accuracy: 0.2459\n",
            "Epoch 129/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.0658 - sparse_categorical_accuracy: 0.2129 - val_loss: 2.0739 - val_sparse_categorical_accuracy: 0.2479\n",
            "Epoch 130/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 2.0600 - sparse_categorical_accuracy: 0.2254 - val_loss: 2.0730 - val_sparse_categorical_accuracy: 0.2473\n",
            "Epoch 131/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - loss: 2.0799 - sparse_categorical_accuracy: 0.2150 - val_loss: 2.0731 - val_sparse_categorical_accuracy: 0.2493\n",
            "Epoch 132/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - loss: 2.0576 - sparse_categorical_accuracy: 0.2178 - val_loss: 2.0716 - val_sparse_categorical_accuracy: 0.2452\n",
            "Epoch 133/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - loss: 2.0697 - sparse_categorical_accuracy: 0.2103 - val_loss: 2.0708 - val_sparse_categorical_accuracy: 0.2466\n",
            "Epoch 134/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - loss: 2.0640 - sparse_categorical_accuracy: 0.2246 - val_loss: 2.0709 - val_sparse_categorical_accuracy: 0.2500\n",
            "Epoch 135/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 123ms/step - loss: 2.0593 - sparse_categorical_accuracy: 0.2283 - val_loss: 2.0704 - val_sparse_categorical_accuracy: 0.2425\n",
            "Epoch 136/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 2.0728 - sparse_categorical_accuracy: 0.2152 - val_loss: 2.0689 - val_sparse_categorical_accuracy: 0.2473\n",
            "Epoch 137/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.0581 - sparse_categorical_accuracy: 0.2170 - val_loss: 2.0690 - val_sparse_categorical_accuracy: 0.2527\n",
            "Epoch 138/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.0582 - sparse_categorical_accuracy: 0.2182 - val_loss: 2.0678 - val_sparse_categorical_accuracy: 0.2500\n",
            "Epoch 139/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.0714 - sparse_categorical_accuracy: 0.2187 - val_loss: 2.0673 - val_sparse_categorical_accuracy: 0.2534\n",
            "Epoch 140/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.0517 - sparse_categorical_accuracy: 0.2246 - val_loss: 2.0667 - val_sparse_categorical_accuracy: 0.2507\n",
            "Epoch 141/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.0659 - sparse_categorical_accuracy: 0.2181 - val_loss: 2.0660 - val_sparse_categorical_accuracy: 0.2514\n",
            "Epoch 142/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.0500 - sparse_categorical_accuracy: 0.2290 - val_loss: 2.0653 - val_sparse_categorical_accuracy: 0.2486\n",
            "Epoch 143/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.0664 - sparse_categorical_accuracy: 0.2133 - val_loss: 2.0643 - val_sparse_categorical_accuracy: 0.2527\n",
            "Epoch 144/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 2.0717 - sparse_categorical_accuracy: 0.2193 - val_loss: 2.0638 - val_sparse_categorical_accuracy: 0.2527\n",
            "Epoch 145/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 2.0659 - sparse_categorical_accuracy: 0.2163 - val_loss: 2.0635 - val_sparse_categorical_accuracy: 0.2527\n",
            "Epoch 146/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 125ms/step - loss: 2.0395 - sparse_categorical_accuracy: 0.2196 - val_loss: 2.0629 - val_sparse_categorical_accuracy: 0.2466\n",
            "Epoch 147/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - loss: 2.0527 - sparse_categorical_accuracy: 0.2213 - val_loss: 2.0625 - val_sparse_categorical_accuracy: 0.2493\n",
            "Epoch 148/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - loss: 2.0598 - sparse_categorical_accuracy: 0.2134 - val_loss: 2.0622 - val_sparse_categorical_accuracy: 0.2541\n",
            "Epoch 149/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.0589 - sparse_categorical_accuracy: 0.2143 - val_loss: 2.0613 - val_sparse_categorical_accuracy: 0.2527\n",
            "Epoch 150/150\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - loss: 2.0701 - sparse_categorical_accuracy: 0.2119 - val_loss: 2.0612 - val_sparse_categorical_accuracy: 0.2541\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c8936fd9d50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model.fit(\n",
        "    X_train_scaled,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=150,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5b18f1e-07c4-4199-b636-9fe8816678ad",
      "metadata": {
        "id": "a5b18f1e-07c4-4199-b636-9fe8816678ad"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}